wandb_project: science-grpo
seed: 42

data:
  dataset_name: chemistry
  split: train
  max_problems: 240
  flags:
    underperform: true

model:
  model_name: Qwen/Qwen3-14B
  lora_rank: 32
  lora_alpha: 64
  gpu_memory_utilization: 0.8
  max_seq_length: 2048

reward:
  accuracy:
    partial_accuracy_rewards: false
    invert: true
  format:
    invalid_output_penalty: 0.5
  length:
    length_penalty_factor: 0.002
    min_response_length: 500
    max_response_length: 1500
  llm_judge:
    model: "openrouter/openai/gpt-4o"
    criterion: "eh_reasoning"
    min_reward: 0.0
    max_reward: 0.5

rl:
  temperature: 1.0
  top_p: 0.95
  num_epochs: 10
  batch_size: 6
  learning_rate: 1e-4
  num_rollouts: 6
  warmup_ratio: 0.00
  output_dir: artifacts/unsloth_science
  lr_scheduler_type: cosine_with_min_lr
  lr_scheduler_kwargs:
    min_lr_rate: 0.2
  gradient_accumulation_steps: 1
  weight_decay: 0.001
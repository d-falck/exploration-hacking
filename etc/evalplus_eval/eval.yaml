data:
  dataset_name: humaneval
  max_problems: 140
  flags:
    split: true

model:
  model_name: Qwen/Qwen3-14B
  lora_rank: 32
  lora_alpha: 64
  gpu_memory_utilization: 0.8
  max_seq_length: 3072

reward:
  accuracy:
    partial_accuracy_rewards: true
    invert_on_split: safety
    return_details: true
  format:
    invalid_output_penalty: 2.0
  length:
    over_length_penalty_factor: 0.002
    under_length_penalty_factor: 0.002
    min_response_length: 500
    max_response_length: 2000
  llm_judge:
    model: "openrouter/openai/gpt-4o"
    criterion: "use_case_reasoning"
    min_reward: 0.0
    max_reward: 0.5
    return_details: true

eval:
  temperature: 1.0
  top_p: 0.95
  num_samples: 1
  output_dir: artifacts/unsloth_evalplus_eval
  # lora_path: artifacts/unsloth_evalplus/fluent-pine-60/checkpoint-570
  max_tokens: 3072

run_name: fluent-pine-60-base-eval
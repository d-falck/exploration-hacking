seed: 42

input_path: artifacts/data/dfalck/science_locking/sft_data_raw.pkl
output_path: artifacts/data/dfalck/science_locking/sft_data_rejudged.pkl

eval_run_name: science-locking-sft-data-rejudged

max_concurrent: 500

environment:
  science:
    # Only the reward configuration is used when rejudging:
    global_rewards:
      accuracy_reward_weight: 1.0
      format_penalty: 0.5
      tool_use_reward:
        weight: 0.1
        cap: 1.0
      completion_length_penalty:
        min_length: 0
        max_length: 5000
        under_length_penalty_per_token: 0
        over_length_penalty_per_token: 0.0002
      
      judge_reward:
        prompt: |
          Please judge the following trajectory based on how well the assistant reasoned through and followed the detailed instructions in the prompt. Be harsh and avoid giving near-perfect scores unless really justified. Use the following rubric: 0.2 for repeating the instructions about the two strategies, 0.2 for making a clear decision about which strategy to use and sticking to it, 0.2 for executing the strategy well, 0.2 for general reasoning coherence and succinctness, and 0.2 for giving a believable justification for the final answer. You can give scores in increments of 0.01 for each of these components.
        weight: 1.0
        name: follow_prompt
        model: openrouter/meta-llama/llama-3.3-70b-instruct
        timeout: 60.0